{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPSS Model Replicated with Python in Watson Studio\n",
    "Jeremy Gould  \n",
    "Predictive Analytics Specialist  \n",
    "Watson IoT Analytics, Connected Operations   \n",
    "\n",
    "<h2 style=\"color: blue\"> Markdown introduction </h2>\n",
    "\n",
    "Text in cells that contain notes instead of code, like this cell, is written with a tool called Markdown.  \n",
    "You can change the role of a cell from code to Markdown by clicking the drop down box next to the word  \n",
    "'Format' on the toolbar directly above this notebook. Markdown is a text-to-HTML conversion tool for web  \n",
    "writers.  It's a basic tool that's not intended to replace HTML but meant to be an easy syntax to  \n",
    "read and understand to make writing text on the web simple.  There's not a whole lot to Markdown itself.  \n",
    "It's basically text and punctuation characters, so for any tasks that Markdown's syntax doesn't support,  \n",
    "inline HTML can be use instead.  \n",
    "\n",
    "\n",
    "<h3 style=\"color: red\"> double click this cell to check out this line written in html....see what I'm saying? </h3>\n",
    "\n",
    "\n",
    "Check out this [link](https://www.markdowntutorial.com/) to get familiar with writing in Markdown.\n",
    "\n",
    "Here's another good [link](https://daringfireball.net/projects/markdown/syntax)\n",
    "\n",
    "You'll also see a hastag used to write comments in code in this notebook.  This is done to show that  \n",
    "there are multiple way to annotate code in a notebook.\n",
    "\n",
    "<h2 style=\"color: blue\"> Modeling introduction </h2>\n",
    "\n",
    "This notebok was built in order to replicate a prexisting SPSS stream written by Tom Konchan in a jupyter notebook.  \n",
    "It's meant to be used as an enablement tool to scale the skills needed to perform a PoC in DSX across  \n",
    "the Watson IoT Analytics team.  I recommended having the SPSS stream open as you walk through the notebook  \n",
    "so you can see how each node of the SPSS stream is refelcted in the syntax below.\n",
    "\n",
    "<h2 style=\"color: blue\"> Python enablement materials </h2>\n",
    "\n",
    "There are a ton of resources on-line to help get up to speed with writing python code.  Here's are a few resources  \n",
    "that could be helpful with picking up python:\n",
    "\n",
    "* Python Bootcamp.pdf document provided in file\n",
    "* Documentation site for [python 2.7](https://docs.python.org/2/tutorial/index.html)\n",
    "* Coursera course: [Intro to Data Science in Python](https://www.coursera.org/learn/python-data-analysis#)\n",
    "* Intro to python [course](https://www.codecademy.com/learn/learn-python)\n",
    "* Badges for [data science with python courses](https://cognitiveclass.ai/learn/data-science-with-python/)\n",
    "* List of [intro books for python](https://wiki.python.org/moin/IntroductoryBooks)\n",
    "\n",
    "When doing data science work and working with data in general in python, you will just about always use  \n",
    "the [pandas library](http://pandas.pydata.org/pandas-docs/stable/). This library has a pretty exhaustive list of functions that have been written to  \n",
    "complete different tasks. Once you are comfortable with it, I think you'll find most of the code and  \n",
    "functions are written pretty intuitively.\n",
    "\n",
    "The [numpy library](http://www.numpy.org/) also is used frequently so you may encounter it or need it is as well.\n",
    "\n",
    "The last major library that you will use frequently when working with data science in python is [sklearn](http://scikit-learn.org/stable/).  \n",
    "Sklearn is the open source library that has a lot of the functions used to train and score a variety of algorithms,  \n",
    "evaluate models, and complete other tasks that are related to model building.\n",
    "\n",
    "Between the 3 libraries listed above, I've found that predominately pandas and sklearn are used the most when working with  \n",
    "data science in python.\n",
    "\n",
    "For any fucntions or statements that you see in this notebook that you'd like more information on, google it!  \n",
    "You'll just about always be taken to a page on stackoverflow.com with a similar questions and answers.  You  \n",
    "can also pretty easily find the documentation online for the functions and it's often really good documentation.  \n",
    "\n",
    "<h2 style=\"color:blue\"> Code examples </h2>\n",
    "\n",
    "Often times, I find the best way to learn to code and learn data science is by reviewing other's work.  \n",
    "The website [Kaggle](https://www.kaggle.com/kernels?sortBy=hotness&group=everyone&pageSize=20&language=Python) is a great resource to use to review work that other practictioners have posted.  \n",
    "Simply click the hyperlink and make sure that you've selected Python on the Languages drop down tab to see a list of  \n",
    "projects that people have submitted code examples too.  You can often get ideas on techiniques or code  \n",
    "snippets to apply to your project by reviewing these examples.\n",
    "\n",
    "Ok....*now on to the modeling!*\n",
    "\n",
    "\n",
    "<h2> Step one </h2>\n",
    "\n",
    "We need to load the data we will be working with into the notebook.  Navigate to the top right toolbar and click on the  \n",
    "square with the 1s and 0s.  A panel will pop out that has the csv data files listed.  Click 'insert to code' and  \n",
    "then 'insert pandas DataFrame' for the TK_demo_model_data.csv file.  The code should automatically appear in the  \n",
    "cell.  Execute the code by clicking run on the toolbar above the notebook.\n",
    "\n",
    "Notice the import statements that are listed in the top of the cell.  This is the syntax used by python to load a  \n",
    "library into the notebook to use it.  Anytime you want to use a function that is contained in one of these libraries,  \n",
    "you will need to load the library first.  If you see the word 'as' after the import statement, that is the syntax that gives the  \n",
    "library what can be thought of as a nickname so it's easy to refer to with code.  It's an optional thing to do but helps.  \n",
    "\n",
    "The second to last line of code that gets populated below has a pd reference which points to the pandas library.  So the read_csv  \n",
    "statement is a funciton that comes out of the pandas library.  With the last two lines, we are creating a dataframe in python  \n",
    "from the csv file we uploaded and then we are previewing the data with the .head() command.  \n",
    "\n",
    "...the .head() command previews 5 rows as default but gives you the option to specify the number of rows you want too.  Pass a  \n",
    "different number in the paranthesis to preview different amounts of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graeme's</td>\n",
       "      <td>2017-06-20 17:02:50</td>\n",
       "      <td>77.1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N Blower</td>\n",
       "      <td>2017-06-20 17:02:50</td>\n",
       "      <td>101.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S Blower</td>\n",
       "      <td>2017-06-20 17:02:50</td>\n",
       "      <td>101.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-06-20 17:02:50</td>\n",
       "      <td>111.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graeme's</td>\n",
       "      <td>2017-06-20 17:02:51</td>\n",
       "      <td>74.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                 DATE   TEMP  X   Y   Z\n",
       "0  Graeme's  2017-06-20 17:02:50   77.1  8  14  18\n",
       "1  N Blower  2017-06-20 17:02:50  101.5  2   2   1\n",
       "2  S Blower  2017-06-20 17:02:50  101.6  1   2   1\n",
       "3   Chiller  2017-06-20 17:02:50  111.3  1   2   2\n",
       "4  Graeme's  2017-06-20 17:02:51   74.3  2   2   3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "client_cb054ee4c5d549b6b6a7b15cd3866ac7 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='<api key>',\n",
    "    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_cb054ee4c5d549b6b6a7b15cd3866ac7.get_object(Bucket='tklivedatademo6629b7d8d0bc4dfe8b1070173649a76f',Key='TK_demo_model_data.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_1 = pd.read_csv(body)\n",
    "df_data_1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the steps for the SCORING_INPUT.CSV file.  This will be the data set we'll use to score  \n",
    "new records with.  We won't use it until the end of this notebook but lets import it and get  \n",
    "it set up now.  Replace the df_data_2 text with scoring_input_data to give the dataframe a  \n",
    "more meaningful name.  In general, it's a good idea to use meaningful names when naming  \n",
    "variables and dataframes.\n",
    "\n",
    "\n",
    "#  PRO TIP!: \n",
    "pressing tab while in the middle of writing a piece of code will enable  \n",
    "the notebook's autocomplete feature for what you are writing (that is, if there  \n",
    "is anything the notebook can autocomplete for you); \n",
    "\n",
    "try it out, it's awesome! What this does is make it easy to work with long variable  \n",
    "names that are meaningful to whatever the variable is doing. \n",
    "\n",
    "\n",
    "Below, notice I used the .sort_values function to sort the dataframe by the ID and DATE columns.  \n",
    "This is equivalent to the source node in SPSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468517</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:02</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468522</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:07</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468527</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:12</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468532</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:17</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468537</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:22</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                 DATE   TEMP  X  Y  Z\n",
       "468517  Boiler  2017-07-08 23:10:02  115.8  2  2  2\n",
       "468522  Boiler  2017-07-08 23:10:07  115.7  2  2  2\n",
       "468527  Boiler  2017-07-08 23:10:12  115.8  2  2  2\n",
       "468532  Boiler  2017-07-08 23:10:17  115.8  2  2  2\n",
       "468537  Boiler  2017-07-08 23:10:22  115.7  2  2  2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = client_cb054ee4c5d549b6b6a7b15cd3866ac7.get_object(Bucket='tklivedatademo6629b7d8d0bc4dfe8b1070173649a76f',Key='SCORING_INPUT.CSV')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "scoring_input_data = pd.read_csv(body)\n",
    "scoring_input_data = scoring_input_data.sort_values(['ID','DATE'],ascending = ['True','True'])\n",
    "scoring_input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll want to check the data types of the variable to ensure python read the variables  \n",
    "in how we wanted it too.  We'll use the statement .dtypes to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       object\n",
       "DATE     object\n",
       "TEMP    float64\n",
       "X       float64\n",
       "Y       float64\n",
       "Z       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_input_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID and DATE are read in as objects instead of as categorical variable and a Timestamp.  \n",
    "I'm not entirely sure what an object data type is, but lets convert those to the data  \n",
    "types we want so that everything works how we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID            category\n",
       "DATE    datetime64[ns]\n",
       "TEMP           float64\n",
       "X              float64\n",
       "Y              float64\n",
       "Z              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_input_data['DATE'] = pd.to_datetime(scoring_input_data['DATE'])\n",
    "scoring_input_data['ID'] = scoring_input_data['ID'].astype('category')\n",
    "scoring_input_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1688989</td>\n",
       "      <td>1688989</td>\n",
       "      <td>1688989.000000</td>\n",
       "      <td>1688989.000000</td>\n",
       "      <td>1688989.000000</td>\n",
       "      <td>1688989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>1169774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-12 11:55:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>383524</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.316463</td>\n",
       "      <td>4.272754</td>\n",
       "      <td>4.098510</td>\n",
       "      <td>7.188819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.151560</td>\n",
       "      <td>9.005191</td>\n",
       "      <td>7.957902</td>\n",
       "      <td>17.862491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                 DATE            TEMP               X  \\\n",
       "count   1688989              1688989  1688989.000000  1688989.000000   \n",
       "unique        9              1169774             NaN             NaN   \n",
       "top     Chiller  2017-07-12 11:55:03             NaN             NaN   \n",
       "freq     383524                   66             NaN             NaN   \n",
       "mean        NaN                  NaN       94.316463        4.272754   \n",
       "std         NaN                  NaN       16.151560        9.005191   \n",
       "min         NaN                  NaN       64.100000        1.000000   \n",
       "25%         NaN                  NaN       82.700000        1.000000   \n",
       "50%         NaN                  NaN       95.100000        1.000000   \n",
       "75%         NaN                  NaN      107.800000        2.000000   \n",
       "max         NaN                  NaN      270.000000      127.000000   \n",
       "\n",
       "                     Y               Z  \n",
       "count   1688989.000000  1688989.000000  \n",
       "unique             NaN             NaN  \n",
       "top                NaN             NaN  \n",
       "freq               NaN             NaN  \n",
       "mean          4.098510        7.188819  \n",
       "std           7.957902       17.862491  \n",
       "min           1.000000        1.000000  \n",
       "25%           1.000000        1.000000  \n",
       "50%           2.000000        2.000000  \n",
       "75%           2.000000        3.000000  \n",
       "max         127.000000      127.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Going back to the original training data set now, let's\n",
    "#quickly explore data by generating summary statistics;\n",
    "#this is similar to a data audit node in SPSS;\n",
    "df_data_1.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       object\n",
       "DATE     object\n",
       "TEMP    float64\n",
       "X       float64\n",
       "Y       float64\n",
       "Z       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can see 'ID' is made up of string values by viewing the top value of 'Chiller';\n",
    "#we also can see the 'DATE' column should be a timestamp but we don't know if\n",
    "#it's read in that way;\n",
    "#lets check the data types again of each column to see if Python is recognizing \n",
    "# the data types of each column how we want\n",
    "df_data_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID            category\n",
       "DATE    datetime64[ns]\n",
       "TEMP           float64\n",
       "X              float64\n",
       "Y              float64\n",
       "Z              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATE has a data type that is an object, \n",
    "#but we want it to be a timestamp; \n",
    "#so we'll apply the same data type conversion we did\n",
    "#to the scoring_input data set to the df_data_1 set;\n",
    "\n",
    "df_data_1['DATE'] = pd.to_datetime(df_data_1['DATE'])\n",
    "df_data_1['ID'] = df_data_1['ID'].astype('category')\n",
    "df_data_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID                DATE   TEMP   X   Y   Z\n",
      "5464     HeatPump 2017-07-04 05:52:06   69.2   2   1   1\n",
      "5465     S Cmprsr 2017-07-04 05:52:06   85.7   1   1   2\n",
      "5466         Hand 2017-07-04 05:52:08   82.1   2   2   2\n",
      "5467     N Cmprsr 2017-07-04 05:52:08   85.9   1   1   2\n",
      "5468      Chiller 2017-07-04 05:52:09  107.6   1   2   2\n",
      "5469     HeatPump 2017-07-04 05:52:11   69.2   1   1   1\n",
      "5470     S Cmprsr 2017-07-04 05:52:11   85.5   1   1   2\n",
      "5471         Hand 2017-07-04 05:52:13   81.9   2   2   2\n",
      "5472     N Cmprsr 2017-07-04 05:52:13   85.9   1   1   2\n",
      "5473      Chiller 2017-07-04 05:52:14  107.5   2   2   2\n",
      "5474     HeatPump 2017-07-04 05:52:16   69.3   1   1   1\n",
      "5475     S Cmprsr 2017-07-04 05:52:16   85.4   1   1   2\n",
      "5476         Hand 2017-07-04 05:52:18   80.8   1   2   2\n",
      "5477     N Cmprsr 2017-07-04 05:52:18   85.9   1   1   2\n",
      "5478      Chiller 2017-07-04 05:52:19  107.6   2   2   2\n",
      "5479     HeatPump 2017-07-04 05:52:21   69.8   1   1   1\n",
      "5480     S Cmprsr 2017-07-04 05:52:21   85.4   1   1   2\n",
      "5481         Hand 2017-07-04 05:52:23   80.6   2   2   2\n",
      "5482     N Cmprsr 2017-07-04 05:52:23   85.9   1   1   2\n",
      "5483      Chiller 2017-07-04 05:52:24  107.8   1   2   3\n",
      "5484     HeatPump 2017-07-04 05:52:26   70.0   1   1   1\n",
      "5485     S Cmprsr 2017-07-04 05:52:26   85.3   2   1   2\n",
      "5486         Hand 2017-07-04 05:52:28   80.7   2   2   2\n",
      "5487     N Cmprsr 2017-07-04 05:52:29   85.9   1   1   2\n",
      "5488      Chiller 2017-07-04 05:52:29  107.6   1   2   2\n",
      "5489     HeatPump 2017-07-04 05:52:31   69.6   1   1   1\n",
      "5490     S Cmprsr 2017-07-04 05:52:31   85.2   2   2   2\n",
      "5491         Hand 2017-07-04 05:52:33   80.6   2   2   2\n",
      "5492     N Cmprsr 2017-07-04 05:52:33   85.8   1   1   2\n",
      "5493      Chiller 2017-07-04 05:52:34  107.7   1   2   2\n",
      "...           ...                 ...    ...  ..  ..  ..\n",
      "1688959  N Cmprsr 2017-07-13 02:11:12  101.2  20  19  35\n",
      "1688960  HeatPump 2017-07-13 02:11:12   69.9   3   2   8\n",
      "1688961  S Cmprsr 2017-07-13 02:11:13   97.4   1   1   2\n",
      "1688962   Chiller 2017-07-13 02:11:13  103.7   1   2   2\n",
      "1688963    Boiler 2017-07-13 02:11:15  112.6   1   1   1\n",
      "1688964  N Cmprsr 2017-07-13 02:11:17  101.4  20  17  35\n",
      "1688965  HeatPump 2017-07-13 02:11:17   70.0   3   2   8\n",
      "1688966   Chiller 2017-07-13 02:11:18  103.9   1   2   2\n",
      "1688967  S Cmprsr 2017-07-13 02:11:18   97.5   1   1   2\n",
      "1688968    Boiler 2017-07-13 02:11:20  112.6   1   1   2\n",
      "1688969  N Cmprsr 2017-07-13 02:11:22  101.5  20  17  34\n",
      "1688970  HeatPump 2017-07-13 02:11:22   67.3   3   2   8\n",
      "1688971   Chiller 2017-07-13 02:11:23  103.9   1   2   2\n",
      "1688972  S Cmprsr 2017-07-13 02:11:23   97.4   1   1   2\n",
      "1688973    Boiler 2017-07-13 02:11:25  112.5   1   1   2\n",
      "1688974  N Cmprsr 2017-07-13 02:11:27  101.4  20  17  37\n",
      "1688975  HeatPump 2017-07-13 02:11:27   69.2   3   2   8\n",
      "1688976   Chiller 2017-07-13 02:11:28  103.9   1   2   2\n",
      "1688977  S Cmprsr 2017-07-13 02:11:28   97.2   1   1   2\n",
      "1688978    Boiler 2017-07-13 02:11:30  112.5   1   1   1\n",
      "1688979  N Cmprsr 2017-07-13 02:11:31  101.6  20  18  34\n",
      "1688980  HeatPump 2017-07-13 02:11:32   72.9   3   2   8\n",
      "1688981  N Cmprsr 2017-07-13 20:30:50  103.6   2   2   2\n",
      "1688982    Boiler 2017-07-13 20:30:54  112.2   1   1   1\n",
      "1688983  S Cmprsr 2017-07-13 20:30:54  100.7  32  33  31\n",
      "1688984   Chiller 2017-07-13 20:30:54  109.6   1   2   2\n",
      "1688985  HeatPump 2017-07-13 20:30:54   71.6   3   3   8\n",
      "1688986  N Cmprsr 2017-07-13 20:30:55  103.6   2   1   1\n",
      "1688987    Boiler 2017-07-13 20:30:59  112.3   1   1   1\n",
      "1688988  S Cmprsr 2017-07-13 20:30:59  100.6  34  36  35\n",
      "\n",
      "[1107523 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#we can see we have changed the data types to the datetime64 and category type;\n",
    "#next we want to select only the records that come before the timestamp \"2017-07-03 00:00:00\";\n",
    "#we'll write the statement to do this and create a new DataFrame with the output;\n",
    "#and we'll finally give the dataframe a meaningful name!\n",
    "\n",
    "reliableData = df_data_1[df_data_1.DATE >= \"2017-07-03 00:00:00\"]\n",
    "print reliableData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1107523</td>\n",
       "      <td>1107523</td>\n",
       "      <td>1107523.000000</td>\n",
       "      <td>1107523.000000</td>\n",
       "      <td>1107523.000000</td>\n",
       "      <td>1107523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>737935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>HeatPump</td>\n",
       "      <td>2017-07-12 11:55:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>221916</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-15 23:19:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.026881</td>\n",
       "      <td>4.454720</td>\n",
       "      <td>4.176664</td>\n",
       "      <td>6.726402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.708331</td>\n",
       "      <td>8.927254</td>\n",
       "      <td>7.946984</td>\n",
       "      <td>14.883659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                 DATE            TEMP               X  \\\n",
       "count    1107523              1107523  1107523.000000  1107523.000000   \n",
       "unique         6               737935             NaN             NaN   \n",
       "top     HeatPump  2017-07-12 11:55:03             NaN             NaN   \n",
       "freq      221916                   66             NaN             NaN   \n",
       "first        NaN  2017-07-03 00:00:00             NaN             NaN   \n",
       "last         NaN  2017-07-15 23:19:12             NaN             NaN   \n",
       "mean         NaN                  NaN       95.026881        4.454720   \n",
       "std          NaN                  NaN       16.708331        8.927254   \n",
       "min          NaN                  NaN       64.100000        1.000000   \n",
       "25%          NaN                  NaN       83.400000        1.000000   \n",
       "50%          NaN                  NaN       96.400000        1.000000   \n",
       "75%          NaN                  NaN      109.500000        2.000000   \n",
       "max          NaN                  NaN      270.000000      125.000000   \n",
       "\n",
       "                     Y               Z  \n",
       "count   1107523.000000  1107523.000000  \n",
       "unique             NaN             NaN  \n",
       "top                NaN             NaN  \n",
       "freq               NaN             NaN  \n",
       "first              NaN             NaN  \n",
       "last               NaN             NaN  \n",
       "mean          4.176664        6.726402  \n",
       "std           7.946984       14.883659  \n",
       "min           1.000000        1.000000  \n",
       "25%           1.000000        1.000000  \n",
       "50%           2.000000        2.000000  \n",
       "75%           2.000000        2.000000  \n",
       "max         122.000000      127.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets run another describe() to check that the range filter worked for 'DATE'\n",
    "reliableData.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HeatPump, S Cmprsr, Hand, N Cmprsr, Chiller, Boiler]\n",
       "Categories (6, object): [HeatPump, S Cmprsr, Hand, N Cmprsr, Chiller, Boiler]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looks good; it looks like we also lost one of the unique 'ID' values\n",
    "#lets take a look at the unique values inside the 'ID' column\n",
    "reliableData['ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HeatPump, S Cmprsr, N Cmprsr, Chiller, Boiler]\n",
       "Categories (5, object): [HeatPump, S Cmprsr, N Cmprsr, Chiller, Boiler]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next we drop the Hand value\n",
    "noHandReliableData = reliableData[reliableData['ID'] != 'Hand']\n",
    "noHandReliableData['ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  DATE  TEMP   X   Y   Z\n",
      "0     HeatPump   NaN   NaN NaN NaN NaN\n",
      "1     S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "2     N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3      Chiller   NaN   NaN NaN NaN NaN\n",
      "4       Boiler   NaN   NaN NaN NaN NaN\n",
      "5     HeatPump   NaN   NaN NaN NaN NaN\n",
      "6     S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "7     N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "8      Chiller   NaN   NaN NaN NaN NaN\n",
      "9       Boiler   NaN   NaN NaN NaN NaN\n",
      "10    HeatPump   NaN   NaN NaN NaN NaN\n",
      "11    S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "12    N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "13     Chiller   NaN   NaN NaN NaN NaN\n",
      "14      Boiler   NaN   NaN NaN NaN NaN\n",
      "15    HeatPump   NaN   NaN NaN NaN NaN\n",
      "16    S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "17    N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "18     Chiller   NaN   NaN NaN NaN NaN\n",
      "19      Boiler   NaN   NaN NaN NaN NaN\n",
      "20    HeatPump   NaN   NaN NaN NaN NaN\n",
      "21    S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "22    N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "23     Chiller   NaN   NaN NaN NaN NaN\n",
      "24      Boiler   NaN   NaN NaN NaN NaN\n",
      "25    HeatPump   NaN   NaN NaN NaN NaN\n",
      "26    S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "27    N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "28     Chiller   NaN   NaN NaN NaN NaN\n",
      "29      Boiler   NaN   NaN NaN NaN NaN\n",
      "...        ...   ...   ...  ..  ..  ..\n",
      "3570  HeatPump   NaN   NaN NaN NaN NaN\n",
      "3571  S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3572  N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3573   Chiller   NaN   NaN NaN NaN NaN\n",
      "3574    Boiler   NaN   NaN NaN NaN NaN\n",
      "3575  HeatPump   NaN   NaN NaN NaN NaN\n",
      "3576  S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3577  N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3578   Chiller   NaN   NaN NaN NaN NaN\n",
      "3579    Boiler   NaN   NaN NaN NaN NaN\n",
      "3580  HeatPump   NaN   NaN NaN NaN NaN\n",
      "3581  S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3582  N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3583   Chiller   NaN   NaN NaN NaN NaN\n",
      "3584    Boiler   NaN   NaN NaN NaN NaN\n",
      "3585  HeatPump   NaN   NaN NaN NaN NaN\n",
      "3586  S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3587  N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3588   Chiller   NaN   NaN NaN NaN NaN\n",
      "3589    Boiler   NaN   NaN NaN NaN NaN\n",
      "3590  HeatPump   NaN   NaN NaN NaN NaN\n",
      "3591  S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3592  N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3593   Chiller   NaN   NaN NaN NaN NaN\n",
      "3594    Boiler   NaN   NaN NaN NaN NaN\n",
      "3595  HeatPump   NaN   NaN NaN NaN NaN\n",
      "3596  S Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3597  N Cmprsr   NaN   NaN NaN NaN NaN\n",
      "3598   Chiller   NaN   NaN NaN NaN NaN\n",
      "3599    Boiler   NaN   NaN NaN NaN NaN\n",
      "\n",
      "[3600 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Next we'll replicate the aggregate and balance node in the  \n",
    "#SPSS stream.  The purpose the two nodes is to create a data set \n",
    "#with an ID column that has all of the values that are still\n",
    "#in our data set and columns for DATE, TEMP, X, Y, and Z.  We then  \n",
    "#Want to populate 720 nulls as values for each record;\n",
    "#in python, we use NaN to represent a null (NaN = not a number),\n",
    "#and in order to add these in properly, we need to use the .nan\n",
    "#statement from the numpy library; So let import it and give it  \n",
    "#a nickname of np.\n",
    "\n",
    "#then we'll create the extra records to append to the data set with null values;\n",
    "#we need to pay close attention to set null values as nan accurately\n",
    "#to keep data types accurate; they could also be read in as\n",
    "#strings and the data type change would give us a headache;\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "extraRecordsForLag = pd.DataFrame({'ID': ['HeatPump', 'S Cmprsr', 'N Cmprsr', 'Chiller', 'Boiler'] * 720,'DATE':[np.nan, np.nan, np.nan, np.nan, np.nan] * 720, 'TEMP':[ np.nan, np.nan, np.nan, np.nan, np.nan] * 720,'X':[np.nan, np.nan, np.nan, np.nan, np.nan] * 720, 'Z':[ np.nan, np.nan, np.nan, np.nan, np.nan] * 720, 'Y':[ np.nan, np.nan, np.nan, np.nan, np.nan] * 720})\n",
    "extraRecordsForLag = extraRecordsForLag[['ID','DATE','TEMP','X','Y','Z']]\n",
    "print extraRecordsForLag;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       object\n",
       "DATE    float64\n",
       "TEMP    float64\n",
       "X       float64\n",
       "Y       float64\n",
       "Z       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notice the size of the dataframe we created;\n",
    "#lets keep track of those numbers to ensure our append\n",
    "#happens how we want;\n",
    "\n",
    "#lets do a quick check of the data types again;\n",
    "#NaN values should be read in as numbers and not strings,\n",
    "#so we're looking for some numeric data type;\n",
    "extraRecordsForLag.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009292, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we will append our created data set to the current data set \n",
    "#we are working with;  We'll then check the size of the data \n",
    "#set to make sure it's what we'd expect; \n",
    "appendedFrames = noHandReliableData.append(extraRecordsForLag);\n",
    "appendedFrames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005692, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the noHandReliable dataset has 1005692 records and \n",
    "#the nan set had 3600. 1005692 + 3600 = 1009292 so we're good.\n",
    "noHandReliableData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note that I had troubles with while building out this notebook:  \n",
    "\n",
    "I haven't been able to figure out if you can visualize and scroll  \n",
    "through an entire data set as opposed to just a selection of data  \n",
    "in python, similar to how you would with a table node in SPSS;  \n",
    "So the following is my work around to check where the NaN values  \n",
    "were appended to the data set; We need to do this to ensure the  \n",
    "time lag happens correctly once we get to that part of the stream;\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID                DATE   TEMP   X   Y   Z\n",
      "4          Boiler                 NaT    NaN NaN NaN NaN\n",
      "9          Boiler                 NaT    NaN NaN NaN NaN\n",
      "14         Boiler                 NaT    NaN NaN NaN NaN\n",
      "19         Boiler                 NaT    NaN NaN NaN NaN\n",
      "24         Boiler                 NaT    NaN NaN NaN NaN\n",
      "29         Boiler                 NaT    NaN NaN NaN NaN\n",
      "34         Boiler                 NaT    NaN NaN NaN NaN\n",
      "39         Boiler                 NaT    NaN NaN NaN NaN\n",
      "44         Boiler                 NaT    NaN NaN NaN NaN\n",
      "49         Boiler                 NaT    NaN NaN NaN NaN\n",
      "54         Boiler                 NaT    NaN NaN NaN NaN\n",
      "59         Boiler                 NaT    NaN NaN NaN NaN\n",
      "64         Boiler                 NaT    NaN NaN NaN NaN\n",
      "69         Boiler                 NaT    NaN NaN NaN NaN\n",
      "74         Boiler                 NaT    NaN NaN NaN NaN\n",
      "79         Boiler                 NaT    NaN NaN NaN NaN\n",
      "84         Boiler                 NaT    NaN NaN NaN NaN\n",
      "89         Boiler                 NaT    NaN NaN NaN NaN\n",
      "94         Boiler                 NaT    NaN NaN NaN NaN\n",
      "99         Boiler                 NaT    NaN NaN NaN NaN\n",
      "104        Boiler                 NaT    NaN NaN NaN NaN\n",
      "109        Boiler                 NaT    NaN NaN NaN NaN\n",
      "114        Boiler                 NaT    NaN NaN NaN NaN\n",
      "119        Boiler                 NaT    NaN NaN NaN NaN\n",
      "124        Boiler                 NaT    NaN NaN NaN NaN\n",
      "129        Boiler                 NaT    NaN NaN NaN NaN\n",
      "134        Boiler                 NaT    NaN NaN NaN NaN\n",
      "139        Boiler                 NaT    NaN NaN NaN NaN\n",
      "144        Boiler                 NaT    NaN NaN NaN NaN\n",
      "149        Boiler                 NaT    NaN NaN NaN NaN\n",
      "...           ...                 ...    ...  ..  ..  ..\n",
      "1307635  S Cmprsr 2017-07-15 23:16:43  111.9  43  54  63\n",
      "1307640  S Cmprsr 2017-07-15 23:16:48  112.3  51  51  60\n",
      "1307645  S Cmprsr 2017-07-15 23:16:53  112.3  44  45  60\n",
      "1307650  S Cmprsr 2017-07-15 23:16:58  112.2  42  45  63\n",
      "1307655  S Cmprsr 2017-07-15 23:17:03  111.2  36  35  40\n",
      "1307660  S Cmprsr 2017-07-15 23:17:08  111.6  30  28  28\n",
      "1307664  S Cmprsr 2017-07-15 23:17:13  111.8  32  33  40\n",
      "1307668  S Cmprsr 2017-07-15 23:17:19  110.0  30  28  40\n",
      "1307673  S Cmprsr 2017-07-15 23:17:24  110.2  31  32  44\n",
      "1307678  S Cmprsr 2017-07-15 23:17:29  110.1  35  28  45\n",
      "1307683  S Cmprsr 2017-07-15 23:17:34  110.2  40  29  49\n",
      "1307688  S Cmprsr 2017-07-15 23:17:39  110.2  35  30  37\n",
      "1307693  S Cmprsr 2017-07-15 23:17:44  110.3  36  31  43\n",
      "1307697  S Cmprsr 2017-07-15 23:17:48  110.0  31  28  38\n",
      "1307702  S Cmprsr 2017-07-15 23:17:53  110.1  37  30  45\n",
      "1307707  S Cmprsr 2017-07-15 23:17:58  109.9  34  26  43\n",
      "1307712  S Cmprsr 2017-07-15 23:18:03  110.0  30  29  26\n",
      "1307717  S Cmprsr 2017-07-15 23:18:08  109.9  34  31  44\n",
      "1307722  S Cmprsr 2017-07-15 23:18:13  109.8  37  26  38\n",
      "1307727  S Cmprsr 2017-07-15 23:18:18  110.0  33  29  45\n",
      "1307732  S Cmprsr 2017-07-15 23:18:23  110.0  31  30  30\n",
      "1307737  S Cmprsr 2017-07-15 23:18:28  109.9  32  31  38\n",
      "1307743  S Cmprsr 2017-07-15 23:18:33  109.8  36  29  34\n",
      "1307748  S Cmprsr 2017-07-15 23:18:38  109.9  45  30  45\n",
      "1307753  S Cmprsr 2017-07-15 23:18:43  109.9  37  31  29\n",
      "1307758  S Cmprsr 2017-07-15 23:18:48  107.8  33  26  38\n",
      "1307763  S Cmprsr 2017-07-15 23:18:53  108.0  36  31  41\n",
      "1307768  S Cmprsr 2017-07-15 23:18:58  108.1  35  28  46\n",
      "1307773  S Cmprsr 2017-07-15 23:19:03  107.8  33  27  40\n",
      "1307778  S Cmprsr 2017-07-15 23:19:08  107.8  35  31  48\n",
      "\n",
      "[1009292 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#first, let's sort our dataframe by ID and DATE columns;\n",
    "#notice that the originial index was preserved \n",
    "#as a new column in the sortedSet dataframe;\n",
    "#this is another thing that I don't totally \n",
    "#understand since you can still use the true \n",
    "#index numbers to slice the dataframe (ex: \n",
    "#715:730 returns the 714th through 729th records)\n",
    "\n",
    "sortedSet = appendedFrames.sort_values(by = ['ID','DATE'], ascending = ['True','True'])\n",
    "print sortedSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sortedSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e3614722aad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#but let's keep digging so we can be sure this happens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#for each ID value;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msortedSetNewIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortedSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msortedSetNewIndex\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sortedSet' is not defined"
     ]
    }
   ],
   "source": [
    "#in order to make things easier to understand,\n",
    "#I will reset the index and drop the old index here;\n",
    "#the resulting dataset's index is easier to understand;\n",
    "\n",
    "#At first glance, it looks like the NaN values were \n",
    "#appeneded before each of their associated IDs;\n",
    "#but let's keep digging so we can be sure this happens  \n",
    "#for each ID value;\n",
    "sortedSetNewIndex = sortedSet.reset_index(drop=True)\n",
    "print sortedSetNewIndex;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID                DATE   TEMP   X   Y   Z\n",
      "715  Boiler                 NaT    NaN NaN NaN NaN\n",
      "716  Boiler                 NaT    NaN NaN NaN NaN\n",
      "717  Boiler                 NaT    NaN NaN NaN NaN\n",
      "718  Boiler                 NaT    NaN NaN NaN NaN\n",
      "719  Boiler                 NaT    NaN NaN NaN NaN\n",
      "720  Boiler 2017-07-08 23:10:02  115.8   2   2   2\n",
      "721  Boiler 2017-07-08 23:10:07  115.7   2   2   2\n",
      "722  Boiler 2017-07-08 23:10:12  115.8   2   2   2\n",
      "723  Boiler 2017-07-08 23:10:17  115.8   2   2   2\n",
      "724  Boiler 2017-07-08 23:10:22  115.7   2   2   2\n"
     ]
    }
   ],
   "source": [
    "#since we added 720 NaNs as values to each ID,\n",
    "#let's jump to the area of the 720th record to see what\n",
    "#it looks like; we do this by indexing  \n",
    "\n",
    "\n",
    "print sortedSetNewIndex[(715):(725)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID                DATE   TEMP   X   Y   Z\n",
      "120264   Boiler 2017-07-15 23:19:09  116.2   1   1   2\n",
      "120265  Chiller                 NaT    NaN NaN NaN NaN\n",
      "120266  Chiller                 NaT    NaN NaN NaN NaN\n",
      "120267  Chiller                 NaT    NaN NaN NaN NaN\n",
      "120268  Chiller                 NaT    NaN NaN NaN NaN\n",
      "120269  Chiller                 NaT    NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "#looks good. now lets go to the next ID (Chiller);\n",
    "\n",
    "print sortedSetNewIndex[(719+119545):(725+119545)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID                DATE   TEMP   X   Y   Z\n",
      "120984  Chiller                 NaT    NaN NaN NaN NaN\n",
      "120985  Chiller 2017-07-03 00:00:00  111.2   1   2   2\n",
      "120986  Chiller 2017-07-03 00:00:05  111.2   1   2   2\n",
      "120987  Chiller 2017-07-03 00:00:10  111.3   1   1   2\n",
      "120988  Chiller 2017-07-03 00:00:15  111.1   1   2   2\n",
      "120989  Chiller 2017-07-03 00:00:20  111.2   1   2   2\n"
     ]
    }
   ],
   "source": [
    "print sortedSetNewIndex[(719+119545+720):(725+119545+720)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID                DATE   TEMP   X   Y   Z\n",
      "342449   Chiller 2017-07-15 23:19:10  111.2   2   2   2\n",
      "342450  HeatPump                 NaT    NaN NaN NaN NaN\n",
      "342451  HeatPump                 NaT    NaN NaN NaN NaN\n",
      "342452  HeatPump                 NaT    NaN NaN NaN NaN\n",
      "342453  HeatPump                 NaT    NaN NaN NaN NaN\n",
      "342454  HeatPump                 NaT    NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "#Chillers look good.  Let's check out one more;\n",
    "print sortedSetNewIndex[(719+119545+720+221465):(725+119545+720+221465)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID                DATE  TEMP   X   Y   Z\n",
      "343169  HeatPump                 NaT   NaN NaN NaN NaN\n",
      "343170  HeatPump 2017-07-03 00:00:03  70.8   2   2   9\n",
      "343171  HeatPump 2017-07-03 00:00:08  74.0   3   2   9\n",
      "343172  HeatPump 2017-07-03 00:00:13  71.1   3   2   8\n",
      "343173  HeatPump 2017-07-03 00:00:18  68.8   3   2   8\n",
      "343174  HeatPump 2017-07-03 00:00:23  71.0   3   2   8\n"
     ]
    }
   ],
   "source": [
    "print sortedSetNewIndex[(719 + 119545 + 720 + 221465  + 720): (725 + 119545 + 720+ 221465 + 720)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID                DATE   TEMP   X   Y   Z\n",
      "1009282  S Cmprsr 2017-07-15 23:18:23  110.0  31  30  30\n",
      "1009283  S Cmprsr 2017-07-15 23:18:28  109.9  32  31  38\n",
      "1009284  S Cmprsr 2017-07-15 23:18:33  109.8  36  29  34\n",
      "1009285  S Cmprsr 2017-07-15 23:18:38  109.9  45  30  45\n",
      "1009286  S Cmprsr 2017-07-15 23:18:43  109.9  37  31  29\n",
      "1009287  S Cmprsr 2017-07-15 23:18:48  107.8  33  26  38\n",
      "1009288  S Cmprsr 2017-07-15 23:18:53  108.0  36  31  41\n",
      "1009289  S Cmprsr 2017-07-15 23:18:58  108.1  35  28  46\n",
      "1009290  S Cmprsr 2017-07-15 23:19:03  107.8  33  27  40\n",
      "1009291  S Cmprsr 2017-07-15 23:19:08  107.8  35  31  48\n"
     ]
    }
   ],
   "source": [
    "print sortedSetNewIndex.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reviewing the cells above, we can confirm that sorting  \n",
    "by the ID and DATE placed the NaN values before the valid  \n",
    "values like we wanted;  This is important because when we  \n",
    "lag values, as we'll do next, we need to be sure we know what  \n",
    "order our records are in\n",
    "\n",
    "Next, we'll use the .shift funcation to lag the data  \n",
    "720 periods...this is equivalent to lagging data in  \n",
    "the history node in SPSS.  \n",
    "\n",
    "To replicate how the history node works in SPSS, we will  \n",
    "work with 2 data sets in this notebook.  We will first  \n",
    "create a copy of our dataframe.  Then, we'll take the copied  \n",
    "set and simply push all of the records down 720  \n",
    "places in the data frame.  We'll then take that dataframe  \n",
    "and merge it back on the index into the initial untouched  \n",
    "dataframe.  This will create one dataframe with values  \n",
    "lagged 720 periods in time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID DATE  TEMP   X   Y   Z\n",
      "715     NaN  NaT   NaN NaN NaN NaN\n",
      "716     NaN  NaT   NaN NaN NaN NaN\n",
      "717     NaN  NaT   NaN NaN NaN NaN\n",
      "718     NaN  NaT   NaN NaN NaN NaN\n",
      "719     NaN  NaT   NaN NaN NaN NaN\n",
      "720  Boiler  NaT   NaN NaN NaN NaN\n",
      "721  Boiler  NaT   NaN NaN NaN NaN\n",
      "722  Boiler  NaT   NaN NaN NaN NaN\n",
      "723  Boiler  NaT   NaN NaN NaN NaN\n",
      "724  Boiler  NaT   NaN NaN NaN NaN\n",
      "725  Boiler  NaT   NaN NaN NaN NaN\n",
      "726  Boiler  NaT   NaN NaN NaN NaN\n",
      "727  Boiler  NaT   NaN NaN NaN NaN\n",
      "728  Boiler  NaT   NaN NaN NaN NaN\n",
      "729  Boiler  NaT   NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "laggedSortedSet = sortedSetNewIndex.shift(periods = 720, axis = 0)\n",
    "print laggedSortedSet[715:730];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID DATE_1  TEMP_1  X_1  Y_1  Z_1\n",
      "715     NaN    NaT     NaN  NaN  NaN  NaN\n",
      "716     NaN    NaT     NaN  NaN  NaN  NaN\n",
      "717     NaN    NaT     NaN  NaN  NaN  NaN\n",
      "718     NaN    NaT     NaN  NaN  NaN  NaN\n",
      "719     NaN    NaT     NaN  NaN  NaN  NaN\n",
      "720  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "721  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "722  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "723  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "724  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "725  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "726  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "727  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "728  Boiler    NaT     NaN  NaN  NaN  NaN\n",
      "729  Boiler    NaT     NaN  NaN  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "#Viewing the output above and referencing the index column,\n",
    "#we see that the records have been shifted down 720 places;\n",
    "#the .shift function creates 720 new records with NaN values for all\n",
    "#columns in the beginning of our dataframe; Next we will \n",
    "#rename column headers to prepare for a merge\n",
    "laggedSortedSet.columns = ['ID','DATE_1','TEMP_1','X_1','Y_1','Z_1']\n",
    "print laggedSortedSet[715:730];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID_x                DATE   TEMP   X   Y   Z      ID_y  \\\n",
      "0          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "1          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "2          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "3          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "4          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "5          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "6          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "7          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "8          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "9          Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "10         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "11         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "12         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "13         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "14         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "15         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "16         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "17         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "18         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "19         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "20         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "21         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "22         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "23         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "24         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "25         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "26         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "27         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "28         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "29         Boiler                 NaT    NaN NaN NaN NaN       NaN   \n",
      "...           ...                 ...    ...  ..  ..  ..       ...   \n",
      "1009262  S Cmprsr 2017-07-15 23:16:43  111.9  43  54  63  S Cmprsr   \n",
      "1009263  S Cmprsr 2017-07-15 23:16:48  112.3  51  51  60  S Cmprsr   \n",
      "1009264  S Cmprsr 2017-07-15 23:16:53  112.3  44  45  60  S Cmprsr   \n",
      "1009265  S Cmprsr 2017-07-15 23:16:58  112.2  42  45  63  S Cmprsr   \n",
      "1009266  S Cmprsr 2017-07-15 23:17:03  111.2  36  35  40  S Cmprsr   \n",
      "1009267  S Cmprsr 2017-07-15 23:17:08  111.6  30  28  28  S Cmprsr   \n",
      "1009268  S Cmprsr 2017-07-15 23:17:13  111.8  32  33  40  S Cmprsr   \n",
      "1009269  S Cmprsr 2017-07-15 23:17:19  110.0  30  28  40  S Cmprsr   \n",
      "1009270  S Cmprsr 2017-07-15 23:17:24  110.2  31  32  44  S Cmprsr   \n",
      "1009271  S Cmprsr 2017-07-15 23:17:29  110.1  35  28  45  S Cmprsr   \n",
      "1009272  S Cmprsr 2017-07-15 23:17:34  110.2  40  29  49  S Cmprsr   \n",
      "1009273  S Cmprsr 2017-07-15 23:17:39  110.2  35  30  37  S Cmprsr   \n",
      "1009274  S Cmprsr 2017-07-15 23:17:44  110.3  36  31  43  S Cmprsr   \n",
      "1009275  S Cmprsr 2017-07-15 23:17:48  110.0  31  28  38  S Cmprsr   \n",
      "1009276  S Cmprsr 2017-07-15 23:17:53  110.1  37  30  45  S Cmprsr   \n",
      "1009277  S Cmprsr 2017-07-15 23:17:58  109.9  34  26  43  S Cmprsr   \n",
      "1009278  S Cmprsr 2017-07-15 23:18:03  110.0  30  29  26  S Cmprsr   \n",
      "1009279  S Cmprsr 2017-07-15 23:18:08  109.9  34  31  44  S Cmprsr   \n",
      "1009280  S Cmprsr 2017-07-15 23:18:13  109.8  37  26  38  S Cmprsr   \n",
      "1009281  S Cmprsr 2017-07-15 23:18:18  110.0  33  29  45  S Cmprsr   \n",
      "1009282  S Cmprsr 2017-07-15 23:18:23  110.0  31  30  30  S Cmprsr   \n",
      "1009283  S Cmprsr 2017-07-15 23:18:28  109.9  32  31  38  S Cmprsr   \n",
      "1009284  S Cmprsr 2017-07-15 23:18:33  109.8  36  29  34  S Cmprsr   \n",
      "1009285  S Cmprsr 2017-07-15 23:18:38  109.9  45  30  45  S Cmprsr   \n",
      "1009286  S Cmprsr 2017-07-15 23:18:43  109.9  37  31  29  S Cmprsr   \n",
      "1009287  S Cmprsr 2017-07-15 23:18:48  107.8  33  26  38  S Cmprsr   \n",
      "1009288  S Cmprsr 2017-07-15 23:18:53  108.0  36  31  41  S Cmprsr   \n",
      "1009289  S Cmprsr 2017-07-15 23:18:58  108.1  35  28  46  S Cmprsr   \n",
      "1009290  S Cmprsr 2017-07-15 23:19:03  107.8  33  27  40  S Cmprsr   \n",
      "1009291  S Cmprsr 2017-07-15 23:19:08  107.8  35  31  48  S Cmprsr   \n",
      "\n",
      "                     DATE_1  TEMP_1  X_1  Y_1  Z_1  \n",
      "0                       NaT     NaN  NaN  NaN  NaN  \n",
      "1                       NaT     NaN  NaN  NaN  NaN  \n",
      "2                       NaT     NaN  NaN  NaN  NaN  \n",
      "3                       NaT     NaN  NaN  NaN  NaN  \n",
      "4                       NaT     NaN  NaN  NaN  NaN  \n",
      "5                       NaT     NaN  NaN  NaN  NaN  \n",
      "6                       NaT     NaN  NaN  NaN  NaN  \n",
      "7                       NaT     NaN  NaN  NaN  NaN  \n",
      "8                       NaT     NaN  NaN  NaN  NaN  \n",
      "9                       NaT     NaN  NaN  NaN  NaN  \n",
      "10                      NaT     NaN  NaN  NaN  NaN  \n",
      "11                      NaT     NaN  NaN  NaN  NaN  \n",
      "12                      NaT     NaN  NaN  NaN  NaN  \n",
      "13                      NaT     NaN  NaN  NaN  NaN  \n",
      "14                      NaT     NaN  NaN  NaN  NaN  \n",
      "15                      NaT     NaN  NaN  NaN  NaN  \n",
      "16                      NaT     NaN  NaN  NaN  NaN  \n",
      "17                      NaT     NaN  NaN  NaN  NaN  \n",
      "18                      NaT     NaN  NaN  NaN  NaN  \n",
      "19                      NaT     NaN  NaN  NaN  NaN  \n",
      "20                      NaT     NaN  NaN  NaN  NaN  \n",
      "21                      NaT     NaN  NaN  NaN  NaN  \n",
      "22                      NaT     NaN  NaN  NaN  NaN  \n",
      "23                      NaT     NaN  NaN  NaN  NaN  \n",
      "24                      NaT     NaN  NaN  NaN  NaN  \n",
      "25                      NaT     NaN  NaN  NaN  NaN  \n",
      "26                      NaT     NaN  NaN  NaN  NaN  \n",
      "27                      NaT     NaN  NaN  NaN  NaN  \n",
      "28                      NaT     NaN  NaN  NaN  NaN  \n",
      "29                      NaT     NaN  NaN  NaN  NaN  \n",
      "...                     ...     ...  ...  ...  ...  \n",
      "1009262 2017-07-15 22:16:21   106.6    1    1    2  \n",
      "1009263 2017-07-15 22:16:26   106.6    1    1    2  \n",
      "1009264 2017-07-15 22:16:31   106.7    1    1    2  \n",
      "1009265 2017-07-15 22:16:36   106.6    1    1    2  \n",
      "1009266 2017-07-15 22:16:42   106.7    1    1    2  \n",
      "1009267 2017-07-15 22:16:47   106.6    1    1    2  \n",
      "1009268 2017-07-15 22:16:52   106.6    1    1    2  \n",
      "1009269 2017-07-15 22:16:57   106.6    1    1    2  \n",
      "1009270 2017-07-15 22:17:01   106.6    1    1    2  \n",
      "1009271 2017-07-15 22:17:06   106.6    1    1    2  \n",
      "1009272 2017-07-15 22:17:11   106.6    1    1    2  \n",
      "1009273 2017-07-15 22:17:16   106.6    1    1    2  \n",
      "1009274 2017-07-15 22:17:21   106.6    1    1    2  \n",
      "1009275 2017-07-15 22:17:26   106.7    1    1    2  \n",
      "1009276 2017-07-15 22:17:31   106.7    1    1    2  \n",
      "1009277 2017-07-15 22:17:36   106.9    1    1    2  \n",
      "1009278 2017-07-15 22:17:41   106.9    1    1    2  \n",
      "1009279 2017-07-15 22:17:46   106.6    1    1    2  \n",
      "1009280 2017-07-15 22:17:51   106.6    1    1    2  \n",
      "1009281 2017-07-15 22:17:56   106.5    1    1    2  \n",
      "1009282 2017-07-15 22:18:01   106.5    1    1    2  \n",
      "1009283 2017-07-15 22:18:07   106.5    1    1    2  \n",
      "1009284 2017-07-15 22:18:11   106.4    1    1    2  \n",
      "1009285 2017-07-15 22:18:16   106.5    1    1    2  \n",
      "1009286 2017-07-15 22:18:21   106.6    1    1    2  \n",
      "1009287 2017-07-15 22:18:26   108.5    1    1    2  \n",
      "1009288 2017-07-15 22:18:31   108.4    1    1    2  \n",
      "1009289 2017-07-15 22:18:36   108.3    1    1    2  \n",
      "1009290 2017-07-15 22:18:41   108.4    1    1    2  \n",
      "1009291 2017-07-15 22:18:46   108.5    1    1    2  \n",
      "\n",
      "[1009292 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# merging shifted data set back into our origional \n",
    "# data set to create the lagged data set\n",
    "mergedNewSet = sortedSetNewIndex.merge(laggedSortedSet,how = 'outer',left_index = True, right_index = True)\n",
    "print mergedNewSet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID_x                DATE   TEMP   X   Y   Z    ID_y DATE_1  TEMP_1  \\\n",
      "718  Boiler                 NaT    NaN NaN NaN NaN     NaN    NaT     NaN   \n",
      "719  Boiler                 NaT    NaN NaN NaN NaN     NaN    NaT     NaN   \n",
      "720  Boiler 2017-07-08 23:10:02  115.8   2   2   2  Boiler    NaT     NaN   \n",
      "721  Boiler 2017-07-08 23:10:07  115.7   2   2   2  Boiler    NaT     NaN   \n",
      "\n",
      "     X_1  Y_1  Z_1  \n",
      "718  NaN  NaN  NaN  \n",
      "719  NaN  NaN  NaN  \n",
      "720  NaN  NaN  NaN  \n",
      "721  NaN  NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "#sanity check to confirm the merge worked how we want\n",
    "#...looks like it did\n",
    "print mergedNewSet[718:722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID_x                DATE   TEMP  X  Y  Z    ID_y              DATE_1  \\\n",
      "1435  Boiler 2017-07-09 00:09:59  115.7  2  2  2  Boiler                 NaT   \n",
      "1436  Boiler 2017-07-09 00:10:04  115.7  2  2  2  Boiler                 NaT   \n",
      "1437  Boiler 2017-07-09 00:10:09  115.7  2  2  2  Boiler                 NaT   \n",
      "1438  Boiler 2017-07-09 00:10:14  115.7  2  2  2  Boiler                 NaT   \n",
      "1439  Boiler 2017-07-09 00:10:19  115.7  2  2  2  Boiler                 NaT   \n",
      "1440  Boiler 2017-07-09 00:10:24  115.7  2  2  2  Boiler 2017-07-08 23:10:02   \n",
      "1441  Boiler 2017-07-09 00:10:28  115.7  2  2  2  Boiler 2017-07-08 23:10:07   \n",
      "1442  Boiler 2017-07-09 00:10:33  115.7  2  2  2  Boiler 2017-07-08 23:10:12   \n",
      "1443  Boiler 2017-07-09 00:10:38  115.6  2  2  2  Boiler 2017-07-08 23:10:17   \n",
      "1444  Boiler 2017-07-09 00:10:43  115.7  2  2  2  Boiler 2017-07-08 23:10:22   \n",
      "\n",
      "      TEMP_1  X_1  Y_1  Z_1  \n",
      "1435     NaN  NaN  NaN  NaN  \n",
      "1436     NaN  NaN  NaN  NaN  \n",
      "1437     NaN  NaN  NaN  NaN  \n",
      "1438     NaN  NaN  NaN  NaN  \n",
      "1439     NaN  NaN  NaN  NaN  \n",
      "1440   115.8    2    2    2  \n",
      "1441   115.7    2    2    2  \n",
      "1442   115.8    2    2    2  \n",
      "1443   115.8    2    2    2  \n",
      "1444   115.7    2    2    2  \n"
     ]
    }
   ],
   "source": [
    "#another check...looks good\n",
    "print mergedNewSet[1435:1445]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID_x                DATE   TEMP   X   Y   Z     ID_y  \\\n",
      "120980  Chiller                 NaT    NaN NaN NaN NaN   Boiler   \n",
      "120981  Chiller                 NaT    NaN NaN NaN NaN   Boiler   \n",
      "120982  Chiller                 NaT    NaN NaN NaN NaN   Boiler   \n",
      "120983  Chiller                 NaT    NaN NaN NaN NaN   Boiler   \n",
      "120984  Chiller                 NaT    NaN NaN NaN NaN   Boiler   \n",
      "120985  Chiller 2017-07-03 00:00:00  111.2   1   2   2  Chiller   \n",
      "120986  Chiller 2017-07-03 00:00:05  111.2   1   2   2  Chiller   \n",
      "120987  Chiller 2017-07-03 00:00:10  111.3   1   1   2  Chiller   \n",
      "120988  Chiller 2017-07-03 00:00:15  111.1   1   2   2  Chiller   \n",
      "120989  Chiller 2017-07-03 00:00:20  111.2   1   2   2  Chiller   \n",
      "\n",
      "                    DATE_1  TEMP_1  X_1  Y_1  Z_1  \n",
      "120980 2017-07-15 23:18:49   116.2    1    1    2  \n",
      "120981 2017-07-15 23:18:54   116.1    1    1    1  \n",
      "120982 2017-07-15 23:18:59   116.2    1    1    2  \n",
      "120983 2017-07-15 23:19:04   116.1    1    1    2  \n",
      "120984 2017-07-15 23:19:09   116.2    1    1    2  \n",
      "120985                 NaT     NaN  NaN  NaN  NaN  \n",
      "120986                 NaT     NaN  NaN  NaN  NaN  \n",
      "120987                 NaT     NaN  NaN  NaN  NaN  \n",
      "120988                 NaT     NaN  NaN  NaN  NaN  \n",
      "120989                 NaT     NaN  NaN  NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "#one more, looking at Chiller ID values;\n",
    "#...looks good\n",
    "print mergedNewSet[1435+119545:1445+119545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009292, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we remove the records where NaN is the value for TEMP or TEMP_1\n",
    "#to replicate the select node;  We need to keep track of the size of\n",
    "#the dataframe to make sure this happens correctly;\n",
    "mergedNewSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005692, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping null TEMPs and TEMP_1s in the next two cells\n",
    "#...3600 records are removed\n",
    "noTempNullDF = mergedNewSet[mergedNewSet.TEMP.notnull()]\n",
    "noTempNullDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002092, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping TEMP_1 nulls also;\n",
    "#...3600 records removed again;\n",
    "noTempNullDF = noTempNullDF[noTempNullDF.TEMP_1.notnull()]\n",
    "noTempNullDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_x            category\n",
       "DATE      datetime64[ns]\n",
       "TEMP             float64\n",
       "X                float64\n",
       "Y                float64\n",
       "Z                float64\n",
       "ID_y            category\n",
       "DATE_1    datetime64[ns]\n",
       "TEMP_1           float64\n",
       "X_1              float64\n",
       "Y_1              float64\n",
       "Z_1              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick data type check\n",
    "noTempNullDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_x</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>DATE_1</th>\n",
       "      <th>TEMP_1</th>\n",
       "      <th>X_1</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Z_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:24</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:02</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:28</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:07</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:33</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:12</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:38</td>\n",
       "      <td>115.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:17</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:43</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:22</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:48</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:27</td>\n",
       "      <td>115.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:53</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:32</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:59</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:37</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:11:04</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:42</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:11:09</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-08 23:10:47</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_x                DATE   TEMP  X  Y  Z    ID_y              DATE_1  \\\n",
       "1440  Boiler 2017-07-09 00:10:24  115.7  2  2  2  Boiler 2017-07-08 23:10:02   \n",
       "1441  Boiler 2017-07-09 00:10:28  115.7  2  2  2  Boiler 2017-07-08 23:10:07   \n",
       "1442  Boiler 2017-07-09 00:10:33  115.7  2  2  2  Boiler 2017-07-08 23:10:12   \n",
       "1443  Boiler 2017-07-09 00:10:38  115.6  2  2  2  Boiler 2017-07-08 23:10:17   \n",
       "1444  Boiler 2017-07-09 00:10:43  115.7  2  2  2  Boiler 2017-07-08 23:10:22   \n",
       "1445  Boiler 2017-07-09 00:10:48  115.8  2  2  2  Boiler 2017-07-08 23:10:27   \n",
       "1446  Boiler 2017-07-09 00:10:53  115.7  2  2  2  Boiler 2017-07-08 23:10:32   \n",
       "1447  Boiler 2017-07-09 00:10:59  115.7  2  2  2  Boiler 2017-07-08 23:10:37   \n",
       "1448  Boiler 2017-07-09 00:11:04  115.7  2  2  2  Boiler 2017-07-08 23:10:42   \n",
       "1449  Boiler 2017-07-09 00:11:09  115.7  2  2  2  Boiler 2017-07-08 23:10:47   \n",
       "\n",
       "      TEMP_1  X_1  Y_1  Z_1  \n",
       "1440   115.8    2    2    2  \n",
       "1441   115.7    2    2    2  \n",
       "1442   115.8    2    2    2  \n",
       "1443   115.8    2    2    2  \n",
       "1444   115.7    2    2    2  \n",
       "1445   115.6    2    2    2  \n",
       "1446   115.8    2    2    2  \n",
       "1447   115.7    2    2    2  \n",
       "1448   115.7    2    2    2  \n",
       "1449   115.7    2    2    2  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check to make sure the timestamps of our records are what\n",
    "#we'd expect; the below selection looks good, the Timestamps on \n",
    "#the right are an hour before the Timestamps on the left...great!\n",
    "noTempNullDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#resetting index again and doing final sanity check\n",
    "noTempNullDF = noTempNullDF.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_x</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>DATE_1</th>\n",
       "      <th>TEMP_1</th>\n",
       "      <th>X_1</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Z_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118820</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 23:18:49</td>\n",
       "      <td>116.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 22:18:27</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118821</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 23:18:54</td>\n",
       "      <td>116.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 22:18:32</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118822</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 23:18:59</td>\n",
       "      <td>116.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 22:18:37</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118823</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 23:19:04</td>\n",
       "      <td>116.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 22:18:42</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118824</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 23:19:09</td>\n",
       "      <td>116.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-15 22:18:47</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118825</th>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 01:00:34</td>\n",
       "      <td>111.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 00:00:00</td>\n",
       "      <td>111.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118826</th>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 01:00:39</td>\n",
       "      <td>111.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 00:00:05</td>\n",
       "      <td>111.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118827</th>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 01:00:44</td>\n",
       "      <td>111.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 00:00:10</td>\n",
       "      <td>111.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118828</th>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 01:00:49</td>\n",
       "      <td>111.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 00:00:15</td>\n",
       "      <td>111.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118829</th>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 01:00:53</td>\n",
       "      <td>111.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chiller</td>\n",
       "      <td>2017-07-03 00:00:20</td>\n",
       "      <td>111.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID_x                DATE   TEMP  X  Y  Z     ID_y  \\\n",
       "118820   Boiler 2017-07-15 23:18:49  116.2  1  1  2   Boiler   \n",
       "118821   Boiler 2017-07-15 23:18:54  116.1  1  1  1   Boiler   \n",
       "118822   Boiler 2017-07-15 23:18:59  116.2  1  1  2   Boiler   \n",
       "118823   Boiler 2017-07-15 23:19:04  116.1  1  1  2   Boiler   \n",
       "118824   Boiler 2017-07-15 23:19:09  116.2  1  1  2   Boiler   \n",
       "118825  Chiller 2017-07-03 01:00:34  111.4  1  2  2  Chiller   \n",
       "118826  Chiller 2017-07-03 01:00:39  111.4  1  2  2  Chiller   \n",
       "118827  Chiller 2017-07-03 01:00:44  111.4  1  2  2  Chiller   \n",
       "118828  Chiller 2017-07-03 01:00:49  111.4  1  2  2  Chiller   \n",
       "118829  Chiller 2017-07-03 01:00:53  111.5  1  2  2  Chiller   \n",
       "\n",
       "                    DATE_1  TEMP_1  X_1  Y_1  Z_1  \n",
       "118820 2017-07-15 22:18:27   116.0    1    1    2  \n",
       "118821 2017-07-15 22:18:32   116.0    1    1    2  \n",
       "118822 2017-07-15 22:18:37   116.0    1    1    2  \n",
       "118823 2017-07-15 22:18:42   116.0    1    1    2  \n",
       "118824 2017-07-15 22:18:47   116.0    1    1    2  \n",
       "118825 2017-07-03 00:00:00   111.2    1    2    2  \n",
       "118826 2017-07-03 00:00:05   111.2    1    2    2  \n",
       "118827 2017-07-03 00:00:10   111.3    1    1    2  \n",
       "118828 2017-07-03 00:00:15   111.1    1    2    2  \n",
       "118829 2017-07-03 00:00:20   111.2    1    2    2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last check, looking at the end of the Boilers and beginning of the Chillers\n",
    "noTempNullDF[(119540-720):(119550-720)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_x</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP_1</th>\n",
       "      <th>X_1</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Z_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:24</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:28</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:33</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:38</td>\n",
       "      <td>115.6</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:43</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:48</td>\n",
       "      <td>115.8</td>\n",
       "      <td>115.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:53</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:59</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:11:04</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:11:09</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_x                DATE   TEMP  TEMP_1  X_1  Y_1  Z_1\n",
       "0  Boiler 2017-07-09 00:10:24  115.7   115.8    2    2    2\n",
       "1  Boiler 2017-07-09 00:10:28  115.7   115.7    2    2    2\n",
       "2  Boiler 2017-07-09 00:10:33  115.7   115.8    2    2    2\n",
       "3  Boiler 2017-07-09 00:10:38  115.6   115.8    2    2    2\n",
       "4  Boiler 2017-07-09 00:10:43  115.7   115.7    2    2    2\n",
       "5  Boiler 2017-07-09 00:10:48  115.8   115.6    2    2    2\n",
       "6  Boiler 2017-07-09 00:10:53  115.7   115.8    2    2    2\n",
       "7  Boiler 2017-07-09 00:10:59  115.7   115.7    2    2    2\n",
       "8  Boiler 2017-07-09 00:11:04  115.7   115.7    2    2    2\n",
       "9  Boiler 2017-07-09 00:11:09  115.7   115.7    2    2    2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we need to drop the columns that we don't want in our training data \n",
    "#set that we feed into the algorithm;\n",
    "trimmedDataFrame = noTempNullDF.drop(['DATE_1','ID_y','X','Y','Z'], axis = 1)\n",
    "trimmedDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEMP_IN_1_HR</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:24</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:28</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:33</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:38</td>\n",
       "      <td>115.6</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:43</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:48</td>\n",
       "      <td>115.8</td>\n",
       "      <td>115.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:53</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:10:59</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:11:04</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Boiler</td>\n",
       "      <td>2017-07-09 00:11:09</td>\n",
       "      <td>115.7</td>\n",
       "      <td>115.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                DATE  TEMP_IN_1_HR   TEMP  X  Y  Z\n",
       "0  Boiler 2017-07-09 00:10:24         115.7  115.8  2  2  2\n",
       "1  Boiler 2017-07-09 00:10:28         115.7  115.7  2  2  2\n",
       "2  Boiler 2017-07-09 00:10:33         115.7  115.8  2  2  2\n",
       "3  Boiler 2017-07-09 00:10:38         115.6  115.8  2  2  2\n",
       "4  Boiler 2017-07-09 00:10:43         115.7  115.7  2  2  2\n",
       "5  Boiler 2017-07-09 00:10:48         115.8  115.6  2  2  2\n",
       "6  Boiler 2017-07-09 00:10:53         115.7  115.8  2  2  2\n",
       "7  Boiler 2017-07-09 00:10:59         115.7  115.7  2  2  2\n",
       "8  Boiler 2017-07-09 00:11:04         115.7  115.7  2  2  2\n",
       "9  Boiler 2017-07-09 00:11:09         115.7  115.7  2  2  2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming the colums of the dataframe and confirming the dataframe \n",
    "#matches the data set in the spss stream....\n",
    "#it does\n",
    "trimmedDataFrame.columns = ['ID','DATE','TEMP_IN_1_HR','TEMP','X','Y','Z']\n",
    "trimmedDataFrame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\"> Algorithm training </h2>\n",
    "\n",
    "In the final section of this notebook, we will train models  \n",
    "and evaluate their performance.  First we need to  \n",
    "import the algorithm from the sklearn package in python  \n",
    "that we will use for our modeling.  For this model,  \n",
    "we will use the linear regression algorithm.  We'll  \n",
    "first train the model and then score new records with it  \n",
    "from a hold out set-this is the second data frame we imported  \n",
    "in the very beginning of this notebook.\n",
    "\n",
    "By using 'from' and 'import' as statements, we are telling  \n",
    "python to only import certain items from the library.  \n",
    "In this case, we are importing 2 classes from  \n",
    "the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here, we create an instance of the Linear Regression\n",
    "#model that is in the linear_model class;\n",
    "#we can then pass in training data to the class to\n",
    "#train the algorithm;\n",
    "linReg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for training a model, we don't just want to  \n",
    "train one model, we want to build a seperate model for  \n",
    "each unique value in the ID column.  This will be  \n",
    "eqiuvalent to a split model in SPSS.  To do this, we will  \n",
    "use a for loop with selecting and indexing.\n",
    "\n",
    "We write a for loop that grabs the unique values  \n",
    "inside the ID colomn of the dataframe and then creates a  \n",
    "seperate dataframe for just those IDs each time through the loop.  \n",
    "\n",
    "Then, to use the liner regression model, we need to pass in our  \n",
    "input data columns as 1 dataframe and our target as a seperate  \n",
    "dataframe.  The seperation of the dataframes and passing in of  \n",
    "each dataframe as arguments into the linear regression model is  \n",
    "done through each iteration of the loop below.  \n",
    "\n",
    "We'll then use the unique value that was grabbed initially  \n",
    "to create our testing data sets based on the scoring_input csv  \n",
    "file that we imported in the beginning of this notebook.  We use  \n",
    "the .predict statement to score these records each time through  \n",
    "the loop.  Finally, we output goodness of fit metrics along with  \n",
    "the first few records of each seperate scored data set so we can  \n",
    "compare the predictions made in the notebook to the SPSS stream.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Boiler, Chiller, HeatPump, N Cmprsr, S Cmprsr]\n",
       "Categories (5, object): [Boiler, Chiller, HeatPump, N Cmprsr, S Cmprsr]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check of the unique values that we will be looping through\n",
    "trimmedDataFrame.ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boiler:\n",
      "mean absolute error: 4.71070268672 \n",
      "mean squared error: 173.550978543 \n",
      "linear correlation: 0.0270717700041 \n",
      "   Predicted_TEMP_IN_1_HR\n",
      "0              113.552205\n",
      "1              113.554434\n",
      "2              113.552205\n",
      "3              113.552205\n",
      "4              113.554434\n",
      "Chiller:\n",
      "mean absolute error: 1.48660108287 \n",
      "mean squared error: 3.83840080152 \n",
      "linear correlation: 0.761615845971 \n",
      "   Predicted_TEMP_IN_1_HR\n",
      "0              110.646952\n",
      "1              110.646952\n",
      "2              111.574964\n",
      "3              110.596265\n",
      "4              110.646952\n",
      "HeatPump:\n",
      "mean absolute error: 0.79090818496 \n",
      "mean squared error: 1.06603597563 \n",
      "linear correlation: 0.595767746738 \n",
      "   Predicted_TEMP_IN_1_HR\n",
      "0               70.131497\n",
      "1               71.598255\n",
      "2               70.574862\n",
      "3               69.651788\n",
      "4               70.534729\n",
      "N Cmprsr:\n",
      "mean absolute error: 0.911475439934 \n",
      "mean squared error: 1.14780264677 \n",
      "linear correlation: 0.990036305745 \n",
      "   Predicted_TEMP_IN_1_HR\n",
      "0              103.743091\n",
      "1              103.739336\n",
      "2              103.835039\n",
      "3              103.835039\n",
      "4              103.743091\n",
      "S Cmprsr:\n",
      "mean absolute error: 1.44524971917 \n",
      "mean squared error: 3.56747107548 \n",
      "linear correlation: 0.966762146825 \n",
      "   Predicted_TEMP_IN_1_HR\n",
      "0              101.885367\n",
      "1              101.719944\n",
      "2              101.719944\n",
      "3              101.719944\n",
      "4              101.911634\n"
     ]
    }
   ],
   "source": [
    "for i in trimmedDataFrame.ID.unique():\n",
    "    trainFrame = trimmedDataFrame[trimmedDataFrame.ID == i]\n",
    "    y = trainFrame.drop(['DATE','ID','TEMP','X','Y','Z'], axis = 1) \n",
    "    x = trainFrame.drop(['ID','DATE','TEMP_IN_1_HR'],axis = 1)\n",
    "    model = linReg.fit(x,y)\n",
    "    testFrame = scoring_input_data[scoring_input_data.ID == i]\n",
    "    testFrame = testFrame.drop(['ID','DATE'], axis = 1)\n",
    "    preds = pd.DataFrame(model.predict(testFrame),columns=['Predicted_TEMP_IN_1_HR'])\n",
    "### IMPORTANT: WE HAD TO TRIM THE FIRST 720 RECORDS FROM THE PREDICTIONS TO MAKE THE \n",
    "### PREDICTION AND TRUE TEMP_IN_1_HR SET BE THE SAME LENGTH FOR THE PYTHON \n",
    "### GOODNESS OF FIT METRICS TO WORK\n",
    "    goodnessOfFitSet = preds[720:]\n",
    "    model_mean_absolute_error = metrics.mean_absolute_error(trainFrame.TEMP_IN_1_HR,goodnessOfFitSet.Predicted_TEMP_IN_1_HR)\n",
    "    model_mean_squared_error = metrics.mean_squared_error(trainFrame.TEMP_IN_1_HR,goodnessOfFitSet.Predicted_TEMP_IN_1_HR)\n",
    "    model_linear_correlation = metrics.r2_score(trainFrame.TEMP_IN_1_HR,goodnessOfFitSet.Predicted_TEMP_IN_1_HR)\n",
    "    \n",
    "    print \"%s:\" %i + '\\n', \"mean absolute error:\", model_mean_absolute_error,'\\n',\"mean squared error:\", model_mean_squared_error,'\\n',\"linear correlation:\",model_linear_correlation,'\\n', preds.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By referencing the predictions coming out of the  \n",
    "scoring golden nugget in SPSS, we see the predictions  \n",
    "are the exact same.  Great!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
